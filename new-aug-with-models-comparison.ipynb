{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newdatset.ipynb",
      "provenance": [],
      "mount_file_id": "1tPC0-EPiAMCaFRlCVzoIXI9cdJyckNJj",
      "authorship_tag": "ABX9TyNSnnk0V2J6FsNzSpNLI2bC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahima8178/100-pandas-puzzles/blob/master/new-aug-with-models-comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbh1PdoXHS66",
        "outputId": "3018d2b8-3c2d-41be-9206-8cdb15e3eda0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYvnbS6pHjr8"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/Kaggle\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT-WAdfqHmH3",
        "outputId": "8b2d1cb3-fa03-4f90-f437-7cbba5dea263"
      },
      "source": [
        "%cd /content/drive/MyDrive/Kaggle/SPECT IMG/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Kaggle/SPECT IMG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12cwwoTUR4Lc",
        "outputId": "239ebcc5-117f-4c39-bfce-e7c5b01cfd3e"
      },
      "source": [
        "!pip install opencv-python==4.5.2.54\n",
        "!pip install --upgrade albumentations"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python==4.5.2.54 in /usr/local/lib/python3.7/dist-packages (4.5.2.54)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.2.54) (1.19.5)\n",
            "Collecting albumentations\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/be/3db3cd8af771988748f69eace42047d5edebf01eaa7e1293f3b3f75f989e/albumentations-1.0.0-py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.16.2)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/35/bfc76533f2274cd3da4e2cf255cd13ab9d7f6fc8990c06911e7f8fcc2130/opencv_python_headless-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2MB 79kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Installing collected packages: opencv-python-headless, albumentations\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-1.0.0 opencv-python-headless-4.5.2.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgy-E1tkHn8m"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsNDSDACHqOl",
        "outputId": "32841b4d-f81c-49ad-99f4-43e254431524"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "print('')\n",
        "print('Detailed information:')\n",
        "print('---------------------')\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "\n",
            "Detailed information:\n",
            "---------------------\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13051266789155382024\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14509932544\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 12089584587824537886\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZy41VhyH6KV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input,Dense,GlobalAveragePooling2D,Flatten,concatenate,BatchNormalization, Dropout\n",
        "from tensorflow.keras.applications import InceptionV3,DenseNet121\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Visualize the Train/Val loss\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-UAmrLoRqic",
        "outputId": "0c7a210e-312d-4799-dd4f-15f77f3f02d7"
      },
      "source": [
        "!pip install git+https://github.com/mjkvaak/ImageDataAugmentor"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/mjkvaak/ImageDataAugmentor\n",
            "  Cloning https://github.com/mjkvaak/ImageDataAugmentor to /tmp/pip-req-build-reaeo45g\n",
            "  Running command git clone -q https://github.com/mjkvaak/ImageDataAugmentor /tmp/pip-req-build-reaeo45g\n",
            "Collecting opencv-python>=4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/b3/3878691fec6babd78bbf4c71c720e1831cbb6ada61679613fe2fae080568/opencv_python-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (51.0MB)\n",
            "\u001b[K     |████████████████████████████████| 51.0MB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ImageDataAugmentor==0.0.0) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from ImageDataAugmentor==0.0.0) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ImageDataAugmentor==0.0.0) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ImageDataAugmentor==0.0.0) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.2->ImageDataAugmentor==0.0.0) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ImageDataAugmentor==0.0.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ImageDataAugmentor==0.0.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ImageDataAugmentor==0.0.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ImageDataAugmentor==0.0.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ImageDataAugmentor==0.0.0) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->ImageDataAugmentor==0.0.0) (1.15.0)\n",
            "Building wheels for collected packages: ImageDataAugmentor\n",
            "  Building wheel for ImageDataAugmentor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ImageDataAugmentor: filename=ImageDataAugmentor-0.0.0-cp37-none-any.whl size=29545 sha256=70afa507ceae3fbfd1d9fc9b50e88a4ca9500f747ed70489f27cbd4ca1e99385\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5nq2uw8d/wheels/d9/10/55/6fca35a4072f87d694876d56ece64db3846cf45e1da1c381fe\n",
            "Successfully built ImageDataAugmentor\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python, ImageDataAugmentor\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed ImageDataAugmentor-0.0.0 opencv-python-4.5.2.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93_PqzpTSH3l"
      },
      "source": [
        "import tensorflow as tf\n",
        "from ImageDataAugmentor.image_data_augmentor import *\n",
        "import albumentations"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvkVHxomIQJL"
      },
      "source": [
        "def get_model(model):\n",
        "# Load the pretained model\n",
        "    kwargs =    {'input_shape':(224, 224, 3),\n",
        "                'include_top':False,\n",
        "                'weights':'imagenet',\n",
        "                'pooling':'avg'}\n",
        "    \n",
        "    pretrained_model = model(**kwargs)\n",
        "    pretrained_model.trainable = False\n",
        "    \n",
        "    inputs = pretrained_model.input\n",
        "\n",
        "    x = tf.keras.layers.Dense(1024, activation='relu')(pretrained_model.output)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXrV6yKTS-Yb"
      },
      "source": [
        "\n",
        "AUGMENTATIONS = albumentations.Compose([\n",
        "    albumentations.OneOf([\n",
        "        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n",
        "        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n",
        "    ],p=1),\n",
        "    albumentations.RandomRotate90(p=1),\n",
        "    albumentations.Rotate(p=1),\n",
        "    albumentations.Posterize(p=1),\n",
        "    albumentations.RandomSnow(p=1),\n",
        "    albumentations.VerticalFlip(p=0.8)\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qS4qZBATzfY",
        "outputId": "b53270ee-f858-4b26-d29b-bde4a80b9843"
      },
      "source": [
        "shear_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "zoom_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "width_shift_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "height_shift_range = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "rotation_range = 10 #@param {type:\"slider\", min:0, max:90, step:5}\n",
        "horizontal_flip = True #@param {type:\"boolean\"}\n",
        "vertical_flip = False #@param {type:\"boolean\"}\n",
        "#@markdown Data source (No need to change if the download succeeded.)\n",
        "data_directory = ''\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "train_datagen = ImageDataAugmentor(\n",
        "        rescale=1./255,\n",
        "        augment=AUGMENTATIONS)\n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
        "\n",
        "val_datagen   = ImageDataGenerator(rescale=1./255) \n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=shear_range,\n",
        "    zoom_range=zoom_range,\n",
        "    width_shift_range=width_shift_range,\n",
        "    height_shift_range=height_shift_range,\n",
        "    rotation_range=rotation_range,\n",
        "    horizontal_flip=horizontal_flip,\n",
        "    vertical_flip=vertical_flip) \n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(os.path.join(data_directory, 'TRAIN/'), # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(90,90),\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "    # Data Generator for validation without data augmentation!\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(os.path.join(data_directory, 'VAL/'), # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(90,90),\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1691 images belonging to 2 classes.\n",
            "Found 345 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D74m9nm9IQMU"
      },
      "source": [
        "def create_gen():\n",
        "    # Load the Images with a generator and Data Augmentation\n",
        "    shear_range = 0.1 \n",
        "    zoom_range = 0.1 \n",
        "    width_shift_range = 0.1 \n",
        "    height_shift_range = 0.1 \n",
        "    rotation_range = 10 \n",
        "    horizontal_flip = True \n",
        "    vertical_flip = False \n",
        "    data_directory = ''\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "    train_datagen = ImageDataAugmentor(\n",
        "        rescale=1./255,\n",
        "        augment=AUGMENTATIONS)\n",
        "\n",
        "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "    )\n",
        "\n",
        "    val_datagen   = ImageDataGenerator(rescale=1./255) \n",
        "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=shear_range,\n",
        "    zoom_range=zoom_range,\n",
        "    width_shift_range=width_shift_range,\n",
        "    height_shift_range=height_shift_range,\n",
        "    rotation_range=rotation_range,\n",
        "    horizontal_flip=horizontal_flip,\n",
        "    vertical_flip=vertical_flip) \n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(os.path.join(data_directory, 'TRAIN/'), # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(90,90),\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "    # Data Generator for validation without data augmentation!\n",
        "\n",
        "    val_generator = val_datagen.flow_from_directory(os.path.join(data_directory, 'VAL/'), # this is where you specify the path to the main data folder\n",
        "                                                 target_size=(90,90),\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "    \n",
        "    return train_datagen,val_datagen,train_generator,val_generator"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MFxiMXsIQPR"
      },
      "source": [
        "from time import perf_counter"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCcVELt0IQSU",
        "outputId": "8e8d7361-d17c-4f87-e890-eafdf52faa01"
      },
      "source": [
        "# Dictionary with the models\n",
        "models = {\n",
        "    \"DenseNet121\": {\"model\":tf.keras.applications.DenseNet121, \"perf\":0},\n",
        "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
        "    \"DenseNet169\": {\"model\":tf.keras.applications.DenseNet169, \"perf\":0},\n",
        "    \"DenseNet201\": {\"model\":tf.keras.applications.DenseNet201, \"perf\":0},\n",
        "    \"InceptionResNetV2\": {\"model\":tf.keras.applications.InceptionResNetV2, \"perf\":0},\n",
        "    \"InceptionV3\": {\"model\":tf.keras.applications.InceptionV3, \"perf\":0},\n",
        "    \"MobileNet\": {\"model\":tf.keras.applications.MobileNet, \"perf\":0},\n",
        "    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n",
        "    \"MobileNetV3Large\": {\"model\":tf.keras.applications.MobileNetV3Large, \"perf\":0},\n",
        "    \"MobileNetV3Small\": {\"model\":tf.keras.applications.MobileNetV3Small, \"perf\":0},\n",
        "    \"ResNet101\": {\"model\":tf.keras.applications.ResNet101, \"perf\":0},\n",
        "    \"ResNet101V2\": {\"model\":tf.keras.applications.ResNet101V2, \"perf\":0},\n",
        "    \"ResNet152\": {\"model\":tf.keras.applications.ResNet152, \"perf\":0},\n",
        "    \"ResNet152V2\": {\"model\":tf.keras.applications.ResNet152V2, \"perf\":0},\n",
        "    \"ResNet50\": {\"model\":tf.keras.applications.ResNet50, \"perf\":0},\n",
        "    \"ResNet50V2\": {\"model\":tf.keras.applications.ResNet50V2, \"perf\":0},\n",
        "    \"VGG16\": {\"model\":tf.keras.applications.VGG16, \"perf\":0},\n",
        "    \"VGG19\": {\"model\":tf.keras.applications.VGG19, \"perf\":0},\n",
        "    \"Xception\": {\"model\":tf.keras.applications.Xception, \"perf\":0}\n",
        "}\n",
        "\n",
        "# Create the generators\n",
        "train_datagen,val_datagen,train_generator,val_generator=create_gen()\n",
        "print('\\n')\n",
        "\n",
        "# Fit the models\n",
        "for name, model in models.items():\n",
        "    \n",
        "    # Get the model\n",
        "    m = get_model(model['model'])\n",
        "    models[name]['model'] = m\n",
        "    \n",
        "    start = perf_counter()\n",
        "    \n",
        "    # Fit the model\n",
        "    history = m.fit(train_generator,\n",
        "    steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.n//val_generator.batch_size,\n",
        "    epochs=10,\n",
        "    verbose=2)\n",
        "    \n",
        "    # Sav the duration and the val_accuracy\n",
        "    duration = perf_counter() - start\n",
        "    duration = round(duration,2)\n",
        "    models[name]['perf'] = duration\n",
        "    print(f\"{name:20} trained in {duration} sec\")\n",
        "    \n",
        "    val_acc = history.history['val_accuracy']\n",
        "    models[name]['val_acc'] = [round(v,4) for v in val_acc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1691 images belonging to 2 classes.\n",
            "Found 345 images belonging to 2 classes.\n",
            "\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "26/26 - 772s - loss: 0.7153 - accuracy: 0.7277 - val_loss: 0.3236 - val_accuracy: 0.8719\n",
            "Epoch 2/10\n",
            "26/26 - 98s - loss: 0.3587 - accuracy: 0.8384 - val_loss: 0.2600 - val_accuracy: 0.8938\n",
            "Epoch 3/10\n",
            "26/26 - 96s - loss: 0.2831 - accuracy: 0.8728 - val_loss: 0.2479 - val_accuracy: 0.8906\n",
            "Epoch 4/10\n",
            "26/26 - 96s - loss: 0.2708 - accuracy: 0.8881 - val_loss: 0.2706 - val_accuracy: 0.8938\n",
            "Epoch 5/10\n",
            "26/26 - 96s - loss: 0.2505 - accuracy: 0.9017 - val_loss: 0.2342 - val_accuracy: 0.9062\n",
            "Epoch 6/10\n",
            "26/26 - 96s - loss: 0.2391 - accuracy: 0.9121 - val_loss: 0.2636 - val_accuracy: 0.9125\n",
            "Epoch 7/10\n",
            "26/26 - 96s - loss: 0.2310 - accuracy: 0.9201 - val_loss: 0.2284 - val_accuracy: 0.9125\n",
            "Epoch 8/10\n",
            "26/26 - 96s - loss: 0.2215 - accuracy: 0.9103 - val_loss: 0.3780 - val_accuracy: 0.8719\n",
            "Epoch 9/10\n",
            "26/26 - 95s - loss: 0.2226 - accuracy: 0.9127 - val_loss: 0.2014 - val_accuracy: 0.9187\n",
            "Epoch 10/10\n",
            "26/26 - 96s - loss: 0.1979 - accuracy: 0.9262 - val_loss: 0.2413 - val_accuracy: 0.9125\n",
            "DenseNet121          trained in 1929.76 sec\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "26/26 - 103s - loss: 0.5019 - accuracy: 0.7996 - val_loss: 0.3510 - val_accuracy: 0.8625\n",
            "Epoch 2/10\n",
            "26/26 - 96s - loss: 0.3319 - accuracy: 0.8672 - val_loss: 0.3190 - val_accuracy: 0.8750\n",
            "Epoch 3/10\n",
            "26/26 - 96s - loss: 0.3119 - accuracy: 0.8666 - val_loss: 0.3094 - val_accuracy: 0.8781\n",
            "Epoch 4/10\n",
            "26/26 - 96s - loss: 0.3102 - accuracy: 0.8666 - val_loss: 0.3748 - val_accuracy: 0.8219\n",
            "Epoch 5/10\n",
            "26/26 - 96s - loss: 0.2863 - accuracy: 0.8765 - val_loss: 0.3622 - val_accuracy: 0.8438\n",
            "Epoch 6/10\n",
            "26/26 - 96s - loss: 0.2697 - accuracy: 0.8943 - val_loss: 0.3289 - val_accuracy: 0.8719\n",
            "Epoch 7/10\n",
            "26/26 - 95s - loss: 0.2929 - accuracy: 0.8771 - val_loss: 0.3110 - val_accuracy: 0.8813\n",
            "Epoch 8/10\n",
            "26/26 - 95s - loss: 0.2466 - accuracy: 0.8888 - val_loss: 0.3442 - val_accuracy: 0.8531\n",
            "Epoch 9/10\n",
            "26/26 - 96s - loss: 0.2376 - accuracy: 0.9035 - val_loss: 0.3113 - val_accuracy: 0.8594\n",
            "Epoch 10/10\n",
            "26/26 - 95s - loss: 0.2559 - accuracy: 0.8980 - val_loss: 0.2806 - val_accuracy: 0.8813\n",
            "MobileNetV2          trained in 1192.91 sec\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "26/26 - 111s - loss: 0.6674 - accuracy: 0.7412 - val_loss: 0.3385 - val_accuracy: 0.8656\n",
            "Epoch 2/10\n",
            "26/26 - 99s - loss: 0.3227 - accuracy: 0.8642 - val_loss: 0.3245 - val_accuracy: 0.8562\n",
            "Epoch 3/10\n",
            "26/26 - 99s - loss: 0.2868 - accuracy: 0.8715 - val_loss: 0.2680 - val_accuracy: 0.8781\n",
            "Epoch 4/10\n",
            "26/26 - 98s - loss: 0.2543 - accuracy: 0.8844 - val_loss: 0.2273 - val_accuracy: 0.8938\n",
            "Epoch 5/10\n",
            "26/26 - 98s - loss: 0.2300 - accuracy: 0.9041 - val_loss: 0.2933 - val_accuracy: 0.8906\n",
            "Epoch 6/10\n",
            "26/26 - 98s - loss: 0.2341 - accuracy: 0.9004 - val_loss: 0.2402 - val_accuracy: 0.9000\n",
            "Epoch 7/10\n",
            "26/26 - 101s - loss: 0.1991 - accuracy: 0.9170 - val_loss: 0.2554 - val_accuracy: 0.8781\n",
            "Epoch 8/10\n",
            "26/26 - 99s - loss: 0.2094 - accuracy: 0.9152 - val_loss: 0.2031 - val_accuracy: 0.9156\n",
            "Epoch 9/10\n",
            "26/26 - 99s - loss: 0.1858 - accuracy: 0.9213 - val_loss: 0.2195 - val_accuracy: 0.9156\n",
            "Epoch 10/10\n",
            "26/26 - 99s - loss: 0.2064 - accuracy: 0.9103 - val_loss: 0.3111 - val_accuracy: 0.8656\n",
            "DenseNet169          trained in 1256.94 sec\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74842112/74836368 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "26/26 - 113s - loss: 0.6266 - accuracy: 0.7486 - val_loss: 0.3705 - val_accuracy: 0.8125\n",
            "Epoch 2/10\n",
            "26/26 - 98s - loss: 0.3546 - accuracy: 0.8482 - val_loss: 0.3818 - val_accuracy: 0.8188\n",
            "Epoch 3/10\n",
            "26/26 - 99s - loss: 0.3491 - accuracy: 0.8427 - val_loss: 0.2786 - val_accuracy: 0.8813\n",
            "Epoch 4/10\n",
            "26/26 - 100s - loss: 0.3137 - accuracy: 0.8574 - val_loss: 0.2867 - val_accuracy: 0.8656\n",
            "Epoch 5/10\n",
            "26/26 - 100s - loss: 0.2934 - accuracy: 0.8691 - val_loss: 0.2799 - val_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "26/26 - 100s - loss: 0.2477 - accuracy: 0.8992 - val_loss: 0.2291 - val_accuracy: 0.9031\n",
            "Epoch 7/10\n",
            "26/26 - 100s - loss: 0.2449 - accuracy: 0.8961 - val_loss: 0.2703 - val_accuracy: 0.8813\n",
            "Epoch 8/10\n",
            "26/26 - 100s - loss: 0.2361 - accuracy: 0.8943 - val_loss: 0.2182 - val_accuracy: 0.9031\n",
            "Epoch 9/10\n",
            "26/26 - 100s - loss: 0.2210 - accuracy: 0.9047 - val_loss: 0.2115 - val_accuracy: 0.9094\n",
            "Epoch 10/10\n",
            "26/26 - 99s - loss: 0.2005 - accuracy: 0.9213 - val_loss: 0.2162 - val_accuracy: 0.9156\n",
            "DenseNet201          trained in 1265.86 sec\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "26/26 - 114s - loss: 0.6549 - accuracy: 0.7511 - val_loss: 0.4464 - val_accuracy: 0.8156\n",
            "Epoch 2/10\n",
            "26/26 - 100s - loss: 0.4158 - accuracy: 0.8144 - val_loss: 0.3505 - val_accuracy: 0.8531\n",
            "Epoch 3/10\n",
            "26/26 - 101s - loss: 0.4541 - accuracy: 0.7880 - val_loss: 0.3625 - val_accuracy: 0.8281\n",
            "Epoch 4/10\n",
            "26/26 - 100s - loss: 0.3727 - accuracy: 0.8390 - val_loss: 0.3318 - val_accuracy: 0.8375\n",
            "Epoch 5/10\n",
            "26/26 - 100s - loss: 0.3381 - accuracy: 0.8623 - val_loss: 0.3149 - val_accuracy: 0.8438\n",
            "Epoch 6/10\n",
            "26/26 - 100s - loss: 0.3517 - accuracy: 0.8482 - val_loss: 0.3464 - val_accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "26/26 - 100s - loss: 0.3140 - accuracy: 0.8715 - val_loss: 0.3016 - val_accuracy: 0.8625\n",
            "Epoch 8/10\n",
            "26/26 - 99s - loss: 0.3029 - accuracy: 0.8685 - val_loss: 0.2857 - val_accuracy: 0.8313\n",
            "Epoch 9/10\n",
            "26/26 - 101s - loss: 0.2680 - accuracy: 0.8789 - val_loss: 0.3537 - val_accuracy: 0.8781\n",
            "Epoch 10/10\n",
            "26/26 - 100s - loss: 0.2893 - accuracy: 0.8844 - val_loss: 0.2881 - val_accuracy: 0.8719\n",
            "InceptionResNetV2    trained in 1184.75 sec\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "26/26 - 106s - loss: 0.5711 - accuracy: 0.7455 - val_loss: 0.3766 - val_accuracy: 0.8156\n",
            "Epoch 2/10\n",
            "26/26 - 98s - loss: 0.4401 - accuracy: 0.7916 - val_loss: 0.3551 - val_accuracy: 0.8594\n",
            "Epoch 3/10\n",
            "26/26 - 99s - loss: 0.3929 - accuracy: 0.8233 - val_loss: 0.3292 - val_accuracy: 0.8500\n",
            "Epoch 4/10\n",
            "26/26 - 98s - loss: 0.3727 - accuracy: 0.8291 - val_loss: 0.3537 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "26/26 - 98s - loss: 0.3774 - accuracy: 0.8285 - val_loss: 0.3099 - val_accuracy: 0.8562\n",
            "Epoch 6/10\n",
            "26/26 - 97s - loss: 0.3643 - accuracy: 0.8297 - val_loss: 0.3075 - val_accuracy: 0.8594\n",
            "Epoch 7/10\n",
            "26/26 - 97s - loss: 0.3432 - accuracy: 0.8537 - val_loss: 0.2989 - val_accuracy: 0.8406\n",
            "Epoch 8/10\n",
            "26/26 - 97s - loss: 0.3395 - accuracy: 0.8494 - val_loss: 0.2837 - val_accuracy: 0.8719\n",
            "Epoch 9/10\n",
            "26/26 - 97s - loss: 0.3294 - accuracy: 0.8648 - val_loss: 0.3146 - val_accuracy: 0.8344\n",
            "Epoch 10/10\n",
            "26/26 - 97s - loss: 0.3448 - accuracy: 0.8439 - val_loss: 0.2717 - val_accuracy: 0.8844\n",
            "InceptionV3          trained in 1116.38 sec\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "26/26 - 103s - loss: 0.5811 - accuracy: 0.7824 - val_loss: 0.3614 - val_accuracy: 0.8375\n",
            "Epoch 2/10\n",
            "26/26 - 98s - loss: 0.3360 - accuracy: 0.8599 - val_loss: 0.3669 - val_accuracy: 0.8281\n",
            "Epoch 3/10\n",
            "26/26 - 97s - loss: 0.3073 - accuracy: 0.8636 - val_loss: 0.2883 - val_accuracy: 0.8656\n",
            "Epoch 4/10\n",
            "26/26 - 97s - loss: 0.2795 - accuracy: 0.8881 - val_loss: 0.2635 - val_accuracy: 0.8687\n",
            "Epoch 5/10\n",
            "26/26 - 97s - loss: 0.2829 - accuracy: 0.8826 - val_loss: 0.2460 - val_accuracy: 0.8906\n",
            "Epoch 6/10\n",
            "26/26 - 96s - loss: 0.2390 - accuracy: 0.8980 - val_loss: 0.2345 - val_accuracy: 0.8906\n",
            "Epoch 7/10\n",
            "26/26 - 96s - loss: 0.2626 - accuracy: 0.8869 - val_loss: 0.2521 - val_accuracy: 0.8656\n",
            "Epoch 8/10\n",
            "26/26 - 96s - loss: 0.2243 - accuracy: 0.9023 - val_loss: 0.2433 - val_accuracy: 0.8906\n",
            "Epoch 9/10\n",
            "26/26 - 96s - loss: 0.2241 - accuracy: 0.9146 - val_loss: 0.2640 - val_accuracy: 0.8844\n",
            "Epoch 10/10\n",
            "26/26 - 95s - loss: 0.2162 - accuracy: 0.9127 - val_loss: 0.2230 - val_accuracy: 0.9062\n",
            "MobileNet            trained in 1111.18 sec\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top.h5\n",
            "17612800/17605208 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "26/26 - 104s - loss: 0.6590 - accuracy: 0.6712 - val_loss: 0.6214 - val_accuracy: 0.6969\n",
            "Epoch 2/10\n",
            "26/26 - 97s - loss: 0.6095 - accuracy: 0.6829 - val_loss: 0.6018 - val_accuracy: 0.6875\n",
            "Epoch 3/10\n",
            "26/26 - 98s - loss: 0.5906 - accuracy: 0.6970 - val_loss: 0.5725 - val_accuracy: 0.6719\n",
            "Epoch 4/10\n",
            "26/26 - 98s - loss: 0.5360 - accuracy: 0.7173 - val_loss: 0.5229 - val_accuracy: 0.7156\n",
            "Epoch 5/10\n",
            "26/26 - 98s - loss: 0.5253 - accuracy: 0.7369 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
            "Epoch 6/10\n",
            "26/26 - 99s - loss: 0.5571 - accuracy: 0.7265 - val_loss: 0.5679 - val_accuracy: 0.6938\n",
            "Epoch 7/10\n",
            "26/26 - 100s - loss: 0.4968 - accuracy: 0.7388 - val_loss: 0.5037 - val_accuracy: 0.7281\n",
            "Epoch 8/10\n",
            "26/26 - 100s - loss: 0.4680 - accuracy: 0.7597 - val_loss: 0.5129 - val_accuracy: 0.7125\n",
            "Epoch 9/10\n",
            "26/26 - 97s - loss: 0.4869 - accuracy: 0.7572 - val_loss: 0.4823 - val_accuracy: 0.7375\n",
            "Epoch 10/10\n",
            "26/26 - 99s - loss: 0.4571 - accuracy: 0.7738 - val_loss: 0.4769 - val_accuracy: 0.7563\n",
            "MobileNetV3Large     trained in 1166.2 sec\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top.h5\n",
            "6701056/6698480 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "26/26 - 105s - loss: 0.6454 - accuracy: 0.6798 - val_loss: 0.6226 - val_accuracy: 0.6844\n",
            "Epoch 2/10\n",
            "26/26 - 98s - loss: 0.6239 - accuracy: 0.6872 - val_loss: 0.6248 - val_accuracy: 0.6875\n",
            "Epoch 3/10\n",
            "26/26 - 99s - loss: 0.6283 - accuracy: 0.6872 - val_loss: 0.6255 - val_accuracy: 0.6812\n",
            "Epoch 4/10\n",
            "26/26 - 100s - loss: 0.6263 - accuracy: 0.6859 - val_loss: 0.6055 - val_accuracy: 0.7063\n",
            "Epoch 5/10\n",
            "26/26 - 100s - loss: 0.6204 - accuracy: 0.6872 - val_loss: 0.6145 - val_accuracy: 0.6938\n",
            "Epoch 6/10\n",
            "26/26 - 101s - loss: 0.6212 - accuracy: 0.6890 - val_loss: 0.6304 - val_accuracy: 0.6719\n",
            "Epoch 7/10\n",
            "26/26 - 101s - loss: 0.6252 - accuracy: 0.6816 - val_loss: 0.6182 - val_accuracy: 0.6875\n",
            "Epoch 8/10\n",
            "26/26 - 102s - loss: 0.6228 - accuracy: 0.6841 - val_loss: 0.6183 - val_accuracy: 0.6844\n",
            "Epoch 9/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ki5nFzWIQWe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5HrvwKJH6Pq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF_OwAh6H6SC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hphIv-3tH6Uq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA7MSI48H6XX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6O6-G9iH6aB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzmOwvz-Hsh4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}